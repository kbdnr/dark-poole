---
layout: post
title: Audiot
---

As part of improving my "wEb PrEsEnCe" I am dumping the existing Audiot codebase into a public github repo.  It was previous located in a bitbucket private repository and receiving no changes or love.

The [Audiot code repository is available here](https://github.com/kbdnr/Audiot).  Cloning and building the code should be simple on a windows machine and is currently unsupported on other environments.

The system was developed around the time of a WPF/Prism focused work project, which is visible in the project structuring.  [Prism Library](https://prismlibrary.com/index.html) is a shining example of the hopes and dreams of the WPF development world and is worth checking out if that is something you are into.

## What is Audiot?
Audiot was designed as a hobbyist performance tool primarily for the [DXGPVWZ](https://vimeo.com/448655239) collaborative project in 2018.  One of the primary drives was the absence of graphical tools in this domain.  While  something like [hookpad](https://www.hooktheory.com/hookpad) is many levels more accurate and intricate, it feels more like piano-roll meets excel with no focus on sound design or performance as an end goal.

## User input
While the existing Audiot user input is limited, a lot of interesting results can come about by entering inputs of different lengths.  Each field is first parsed to obtain the listing of values, which are then iterated.

Here is a fun example:
- Prog: 1,2,2,4,5
- Octave: -1,1,0
- Inv: 0,1,2

The system will continue to "wrap" over the values provided, progression step 4 will use octave -1, and inversion 0.  Utilize prime-number sized inputs will create some interesting concepts to emerge over large number of repetitions.

A secondary option allows for midi input to be received and used either directly (note input) or as a trigger for the designed sequence.  While confusing, this functionality was added mainly for interesting concepts to emerge when playing the dg-20 in midi mode 2 (each string playing notes on separate midi channels).

## Why Use Comma-separated text fields
This is a good question. Mostly laziness.

## Possible road-map
Ideas that we'd like to include in the future
- Linking/unlinking device timing for clocking influence
- Scale/Progression or Control Change interpolation between devices
- (Programmable) LFOs for independent control changes (i really want to add this)
- Representation of user input in non-comma separated text fields
- Portable build(s) using ILMerge
- Utilize [avalonia](https://avaloniaui.net/) xaml framework for cross-platform/mono unsupported
- .NET Core targeting
- Port to Unity/OpenXR performance environment
